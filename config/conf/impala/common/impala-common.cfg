[configuration]
  # The raw files need to read when generating the configuration
  log4j.xml=${config_dir}/template/impala/log4j.xml

  [[core-site.xml]]
  # The core-site.xml config content
  fs.defaultFS=hdfs://${cluster.hdfs_cluster}

  hadoop.http.staticuser.user=impala
  hadoop.tmp.dir=/tmp/hadoop
  io.file.buffer.size=131072

  # security authentication switch
  hadoop.security.authentication=simple
  hadoop.security.authorization=false
  hadoop.security.use-weak-http-crypto=false

  [[hdfs-site.xml]]
  # The hdfs-site.xml config content
  dfs.nameservices=${cluster.hdfs_cluster}
  dfs.ha.namenodes.${cluster.hdfs_cluster}="host0,host1"
  dfs.namenode.rpc-address.${cluster.hdfs_cluster}.host0=${hdfs.namenode.host.0}:${hdfs.namenode.base_port}
  dfs.namenode.rpc-address.${cluster.hdfs_cluster}.host1=${hdfs.namenode.host.1}:${hdfs.namenode.base_port}
  dfs.client.failover.proxy.provider.${cluster.hdfs_cluster}=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider

  dfs.client.read.shortcircuit.skip.auth=true
  dfs.client.read.shortcircuit=true

  # namenode security config
  dfs.namenode.kerberos.internal.spnego.principal=HTTP/hadoop@XIAOMI.HADOOP
  dfs.namenode.keytab.file=/etc/hadoop/conf/hdfs.keytab
  dfs.namenode.kerberos.principal=hdfs/hadoop@XIAOMI.HADOOP
  # secondary namenode security config
  dfs.secondary.namenode.kerberos.internal.spnego.principal=HTTP/hadoop@XIAOMI.HADOOP
  dfs.secondary.namenode.keytab.file=/etc/hadoop/conf/hdfs.keytab
  dfs.secondary.namenode.kerberos.principal=hdfs/hadoop@XIAOMI.HADOOP

  # datanode security config
  dfs.datanode.keytab.file=/etc/hadoop/conf/hdfs.keytab
  dfs.datanode.kerberos.principal=hdfs/hadoop@XIAOMI.HADOOP

  [[hive-site.xml]]
  hive.metastore.uris=""

