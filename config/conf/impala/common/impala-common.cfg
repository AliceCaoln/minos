[configuration]
  # The raw files need to read when generating the configuration
  log4j.xml=%{config_dir}/template/impala/log4j.xml
  pre.sh=%{config_dir}/template/impala/pre.sh
  post.sh=%{config_dir}/template/impala/post.sh

  [[core-site.xml]]
    # The core-site.xml config content
    fs.defaultFS=hdfs://%{cluster.hdfs_cluster}

    hadoop.http.staticuser.user=impala
    hadoop.tmp.dir=/tmp/hadoop
    io.file.buffer.size=131072

    # security authentication switch
    hadoop.security.authentication=simple
    hadoop.security.authorization=false
    hadoop.security.use-weak-http-crypto=false

  [[hdfs-site.xml]]
    # The hdfs-site.xml config content
    dfs.nameservices=%{cluster.hdfs_cluster}
    dfs.ha.namenodes.%{cluster.hdfs_cluster}="host0,host1"
    dfs.namenode.rpc-address.%{cluster.hdfs_cluster}.host0=%{hdfs.namenode.0.host}:%{hdfs.namenode.0.base_port}
    dfs.namenode.rpc-address.%{cluster.hdfs_cluster}.host1=%{hdfs.namenode.1.host}:%{hdfs.namenode.1.base_port}
    dfs.client.failover.proxy.provider.%{cluster.hdfs_cluster}=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider

    dfs.client.read.shortcircuit.skip.auth=true
    dfs.client.read.shortcircuit=true

    # namenode security config
    dfs.namenode.kerberos.internal.spnego.principal=HTTP/hadoop@EXAMPLE.HADOOP
    dfs.namenode.keytab.file=/etc/hadoop/conf/hdfs.keytab
    dfs.namenode.kerberos.principal=hdfs/hadoop@EXAMPLE.HADOOP
    # secondary namenode security config
    dfs.secondary.namenode.kerberos.internal.spnego.principal=HTTP/hadoop@EXAMPLE.HADOOP
    dfs.secondary.namenode.keytab.file=/etc/hadoop/conf/hdfs.keytab
    dfs.secondary.namenode.kerberos.principal=hdfs/hadoop@EXAMPLE.HADOOP

    # datanode security config
    dfs.datanode.keytab.file=/etc/hadoop/conf/hdfs.keytab
    dfs.datanode.kerberos.principal=hdfs/hadoop@EXAMPLE.HADOOP

  [[hive-site.xml]]
    hive.metastore.uris=""

[arguments]

  [[service_common]]
    jvm_args='''
    '''

    system_properties='''
    '''

    main_entry='''
    '''

    extra_args='''
      -be_port=%{impalad.base_port+2}
      -state_store_port=%{statestored.base_port}
      -catalog_service_port=%{catalogd.base_port}
      -mem_limit=20%
      -state_store_host=%{statestored.0.host}
      -kerberos_reinit_interval=1200
      -webserver_doc_root=$run_dir/package
      -webserver_interface=%{current_host}
      -log_dir=$run_dir/log
      -v=2
      -logbuflevel=-1
      -sasl_path=$run_dir/package/lib/sasl2
      -principal=%{cluster.kerberos_username}/hadoop@%{cluster.kerberos_realm}
      -keytab_file=%{hadoop_conf_path}/%{cluster.kerberos_username}.keytab
      -tgt_file=$run_dir/impala.tc
      -statestore_max_missed_heartbeats=20
      -statestore_suspect_heartbeats=5
      -catalog_service_host=%{catalogd.0.host}
    '''

  [[impalad]]
    extra_args='''
      -webserver_port=%{impalad.base_port+1}
      -beeswax_port=%{impalad.base_port}
      -hs2_port=%{impalad.base_port+4}
      -state_store_subscriber_port=%{impalad.base_port+3}
    '''

  [[statestored]]
    extra_args='''
      -webserver_port=%{statestored.base_port+1}
    '''

  [[catalogd]]
    extra_args='''
      -webserver_port=%{catalogd.base_port+1}
      -state_store_subscriber_port=%{catalogd.base_port+2}
    '''
